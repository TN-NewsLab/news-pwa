import os
import requests
import feedparser
import json
import sys
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

from openai import OpenAI
from dotenv import load_dotenv
from datetime import datetime, timezone, timedelta
from pathlib import Path

REPO_ROOT = Path(__file__).resolve().parents[1]
DATA_PATH = REPO_ROOT / "docs" / "data" / "summary_v2.json"

DATA_PATH.parent.mkdir(parents=True, exist_ok=True)

# 1) .env èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=API_KEY)

RSS_SOURCES = {
    "ai": {
        "source": "VentureBeat",
        "url": "https://venturebeat.com/feed/"
    },
    "economy": {
        "source": "NHK",
        "url": "https://www3.nhk.or.jp/rss/news/cat5.xml"
    },
    "world": {
        "source": "BBC",
        "url": "https://feeds.bbci.co.uk/news/world/rss.xml"
    },
    "japan_politics": {
        "source": "NHK",
        "url": "https://www3.nhk.or.jp/rss/news/cat3.xml"
    }
}

# ********** RSSå–å¾— **********
def fetch_rss(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    resp = requests.get(url, headers=headers, timeout=10)
    resp.raise_for_status()

    feed = feedparser.parse(resp.content)
    entries = feed.entries
        
    # è¨˜äº‹ãŒç©ºã§ãªã„æ™‚ã ã‘1ä»¶
    return feed.entries[0] if feed.entries else None

def fetch_rss_ai_multiple(url, max_items=2):
    """
    AIã‚«ãƒ†ã‚´ãƒªå°‚ç”¨ï¼šOpenAI/ChatGPTé–¢é€£ã‚’å„ªå…ˆã—ã¤ã¤ã€
    æœ€å¤§ max_items ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¿”ã™é–¢æ•°ã€‚
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }

    resp = requests.get(url, headers=headers, timeout=10)
    resp.raise_for_status()

    feed = feedparser.parse(resp.content)
    entries = feed.entries

    if not entries:
        return []

    keywords = ["openai", "chatgpt", "sam altman", "gpt", "large language model"]

    # --- â‘  å„ªå…ˆè¨˜äº‹ï¼ˆOpenAI/ChatGPTé–¢é€£ï¼‰ã‚’å…ˆã«å–å¾—
    priority_items = []
    normal_items = []

    for e in entries:
        text = (e.title + " " + e.get("summary", "")).lower()
        if any(k in text for k in keywords):
            priority_items.append(e)
        else:
            normal_items.append(e)

    # --- â‘¡ å„ªå…ˆ â†’ é€šå¸¸ ã®é †ã§ max_items ä»¶å–ã‚Šå‡ºã™
    combined = priority_items + normal_items
    return combined[:max_items]

# ********** titleãƒ»summaryæŠ½å‡º / 3è¡Œè¦ç´„ **********
def summarize(text, title=""):
    date_rule = (
            "è¦ç´„ã§ã¯å¹´å·ï¼ˆä¾‹ï¼š2023å¹´ã€2025å¹´ãªã©ï¼‰ã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"
            "æ—¥ä»˜ãŒå¿…è¦ãªå ´åˆã¯ã€Œä»Šå¹´ã€ã€Œæœ€è¿‘ã€ã€Œ9æœˆæœ«æ™‚ç‚¹ã€ãªã©ã®ç›¸å¯¾è¡¨ç¾ã®ã¿ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚"
    )
 
    if not text or text.strip() == "":
        prompt = (
            "æ¬¡ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã€è¨˜äº‹ã®å†…å®¹ã‚’æ¨æ¸¬ã—ã¦3è¡Œã®è¦ç´„æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
            f"{date_rule}\n"
            f"ã‚¿ã‚¤ãƒˆãƒ«: {title}\n"
        )
    else:
            prompt = (
                f"{date_rule}\n"
                f"æ¬¡ã®è¨˜äº‹ã‚’3è¡Œã§è¦ç´„ã—ã¦ãã ã•ã„ï¼š\n{text}"
            )
    # else:
    #      prompt = f"æ¬¡ã®è¨˜äº‹ã‚’3è¡Œã§è¦ç´„ã—ã¦ãã ã•ã„ï¼š\n{text}"
    
    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )

    content = res.choices[0].message.content

    # content ãŒæ–‡å­—åˆ—ã®å ´åˆ
    if isinstance(content, str):
        return content

    # content ãŒé…åˆ—ï¼ˆMessageContentï¼‰ã§è¿”ã‚‹å ´åˆï¼ˆå°†æ¥ã®ä»•æ§˜å¤‰æ›´å¯¾ç­–ï¼‰
    if isinstance(content, list) and len(content) > 0:
        first = content[0]
        # textå±æ€§ã‚’æŒã¤ã‚¿ã‚¤ãƒ—
        if hasattr(first, "text"):
            return first.text
        # ä¸‡ãŒä¸€ text ãŒãªãã¦ã‚‚ string_value ãŒã‚ã‚‹
        if hasattr(first, "string_value"):
            return first.string_value

    # ãã‚Œã§ã‚‚ãƒ€ãƒ¡ãªã‚‰ã€ã¨ã‚Šã‚ãˆãšæ–‡å­—åˆ—åŒ–ã—ã¦è¿”ã™
    return str(content)

# ********** è‹±èªã‚¿ã‚¤ãƒˆãƒ«ï¼†è¦ç´„ â†’ æ—¥æœ¬èªç¿»è¨³ **********
def translate_to_japanese(title_en: str, summary_en: str):
    """
    VentureBeat / BBC ãªã©è‹±èªè¨˜äº‹å°‚ç”¨ã€‚
    ã‚¿ã‚¤ãƒˆãƒ«ã¨è¦ç´„ã‚’ã¾ã¨ã‚ã¦æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹æ–‡ä½“ã«ç¿»è¨³ã™ã‚‹ã€‚
    ã†ã¾ããƒ‘ãƒ¼ã‚¹ã§ããªã‘ã‚Œã°ã€å…ƒã®è‹±èªã‚’ãã®ã¾ã¾è¿”ã™ã€‚
    """
    system_prompt = (
        "You are a professional Japanese news editor.\n"
        "Translate the provided English title and summary into clear, natural Japanese "
        "suitable for news readers. Preserve meaning strictly, avoid embellishment, "
        "and maintain factual accuracy.\n"
        "Return the result as JSON with keys: title_ja, summary_ja."
    )

    user_prompt = f"""
Translate the following text into Japanese.

Title:
{title_en}

Summary:
{summary_en}
""".strip()

    res = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )

    content = res.choices[0].message.content

    if not isinstance(content, str):
        content = str(content)

    text = content.strip()

    # ```json ï½ ``` ã§è¿”ã£ã¦ããŸå ´åˆã®ã‚±ã‚¢
    if text.startswith("```"):
        lines = text.splitlines()
        # ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹è¡Œã‚’å‰Šã‚‹
        lines = [l for l in lines if not l.strip().startswith("```")]
        text = "\n".join(lines).strip()

    title_ja = title_en
    summary_ja = summary_en

    try:
        data = json.loads(text)
        t = data.get("title_ja")
        s = data.get("summary_ja")
        if isinstance(t, str) and t.strip():
            title_ja = t.strip()
        if isinstance(s, str) and s.strip():
            summary_ja = s.strip()
    except Exception as e:
        print("âš ï¸ ç¿»è¨³çµæœã®JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—:", e)
        print("  è¿”å´ãƒ†ã‚­ã‚¹ãƒˆ:", text[:200], "...")

    return title_ja, summary_ja

# ********** ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š **********
def classify_category(title, summary, initial_category):
    text = (title + " " + summary).lower()

    # --- AI ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ---
    ai_keywords = [
        "ai", "artificial intelligence", "gpt", "chatgpt",
        "openai", "neural", "model", "llm", "gemini",
        "anthropic", "deepseek", "ç”Ÿæˆai", "æ©Ÿæ¢°å­¦ç¿’"
    ]

    # --- çµŒæ¸ˆ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ ---
    economy_keywords = [
        "stock", "market", "shares", "inflation", "finance",
        "çµŒæ¸ˆ", "ä¼æ¥­", "æ ª", "æ ªä¾¡", "æ™¯æ°—", "è³ƒé‡‘", "è³‡é‡‘", "é‡‘åˆ©"
    ]

    # --- â‘  AIåˆ¤å®š ---
    # if any(k in text for k in ai_keywords):
    #     return "AI"

    # --- â‘¡ çµŒæ¸ˆåˆ¤å®š ---
    if any(k in text for k in economy_keywords):
        return "çµŒæ¸ˆ"

    # --- â‘¢ ã©ã¡ã‚‰ã§ã‚‚ãªã„å ´åˆ â†’ ãã®ä»– ---
    return "ãã®ä»–"

# ********** timestampç”Ÿæˆ **********
def format_timestamp(entry):
    """
    RSSã®pubDateã‚’JSTã® 'YYYY-MM-DD HH:MM' ã«çµ±ä¸€ã€‚
    pubDateãŒç„¡ã‘ã‚Œã°ç¾åœ¨æ™‚åˆ»ã‚’ä½¿ç”¨ã€‚
    """
    try:
        if hasattr(entry, "published"):
            dt = feedparser._parse_date(entry.published)
        elif hasattr(entry, "updated"):
            dt = feedparser._parse_date(entry.updated)
        else:
            dt = None
    except:
        dt = None

    # pubDateå–å¾—å¤±æ•— â†’ ä»Šã®æ—¥æ™‚ã‚’ä½¿ã†
    if dt is None:
        dt_obj = datetime.now(timezone.utc)
    else:
        dt_obj = datetime(*dt[:6], tzinfo=timezone.utc)

    # JSTã¸å¤‰æ›
    jst = dt_obj.astimezone(timezone(timedelta(hours=9)))

    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    return jst.strftime("%Y-%m-%d %H:%M")

def main():
    output_items = []

    for category, info in RSS_SOURCES.items():
        print(f"\nğŸ” [{info['source']}] RSSå–å¾—ä¸­...")

        # --- AIã‚«ãƒ†ã‚´ãƒªã¯ 2ä»¶ãƒ­ã‚¸ãƒƒã‚¯ ---
        if category == "ai":
            entries = fetch_rss_ai_multiple(info["url"], max_items=2)
        else:
            # --- ãã‚Œä»¥å¤–ã®ã‚«ãƒ†ã‚´ãƒªã¯é€šå¸¸1ä»¶ ---
            entry = fetch_rss(info["url"])
            if not entry:
                print(f"âš ï¸ {info['source']} ã®RSSãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                continue
            entries = [entry]  # â† 1ä»¶ã‚’ãƒªã‚¹ãƒˆåŒ–ã—ã¦çµ±ä¸€å‡¦ç†ã«ã™ã‚‹

        # --- entriesã®å…±é€šå‡¦ç† ---
        for entry in entries:
            title = entry.title
            link = entry.link
            description = entry.summary if hasattr(entry, "summary") else ""

            print(f"ğŸ§  [{info['source']}] è¦ç´„ä¸­...")
            summary = summarize(description, title)

            # â˜… è‹±èªè¨˜äº‹ï¼ˆVentureBeat / BBCï¼‰ã®ã¿æ—¥æœ¬èªç¿»è¨³ã‚’ã‹ã‘ã‚‹
            title_ja = title
            summary_ja = summary
            title_en = ""
            summary_en = ""

            if info["source"] in ["VentureBeat", "BBC"]:
                title_en = title
                summary_en = summary
                print(f"ğŸŒ [{info['source']}] æ—¥æœ¬èªç¿»è¨³ä¸­...")
                title_ja, summary_ja = translate_to_japanese(title_en, summary_en)

            # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®šã¯å¾“æ¥ã©ãŠã‚Šã€Œå…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ï¼‹è¦ç´„ã€ã§è¡Œã†
            if category == "ai":
                category_final = "AI"
            else:            
                category_final = classify_category(title, summary, category)

            timestamp = format_timestamp(entry)

            output_items.append({
                "source": info['source'],
                "title": title_ja,        # æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«
                "title_en": title_en,     # è‹±èªã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè‹±èªè¨˜äº‹ã®ã¿ã€ãã‚Œä»¥å¤–ã¯ç©ºæ–‡å­—ï¼‰
                "summary": summary_ja,    # æ—¥æœ¬èªè¦ç´„
                "summary_en": summary_en, # è‹±èªè¦ç´„ï¼ˆè‹±èªè¨˜äº‹ã®ã¿ã€ãã‚Œä»¥å¤–ã¯ç©ºæ–‡å­—ï¼‰
                "link": link,
                "category": category_final,
                "publishedAt": timestamp
            })

    with open(DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(output_items, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… è¤‡æ•°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¾ã¨ã‚ã¦ {os.path.basename(DATA_PATH)} ã‚’ç”Ÿæˆã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()
